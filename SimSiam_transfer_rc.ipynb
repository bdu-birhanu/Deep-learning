{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gFTq1rLLpxm9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.optimizers import adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import glob\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_20620/2874510872.py:1: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.run_functions_eagerly` instead of the experimental version.\n"
     ]
    }
   ],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fWxQyUYJrAoz"
   },
   "outputs": [],
   "source": [
    "# Retrieve the weights (50 epochs pre-training) of the projection head\n",
    "!wget -q https://github.com/sayakpaul/SimSiam-TF/releases/download/v1.0.0/projection.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mqcYr9UMrNtt",
    "outputId": "c286bf12-4f9b-43ef-d957-436831406f66"
   },
   "outputs": [],
   "source": [
    "#load datset of Amahric charcters\n",
    "# load the train and test datsets\n",
    "x_train=np.load('x_train.npy')\n",
    "x_test= np.load('x_test.npy')\n",
    "y_train=np.load('y_train_231.npy')\n",
    "y_test=np.load('y_test_231.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hoet-encoding of 231 classes\n",
    "Y_train =np_utils.to_categorical(y_train, 231)\n",
    "Y_test = np_utils.to_categorical(y_test, 231)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load lables of the training and test datset interms of row/col\n",
    "y_trainr=np.load('y_trainr.npy')\n",
    "y_trainc=np.load('y_trainc.npy')\n",
    "y_testr=np.load('y_testr.npy')\n",
    "y_testc=np.load('y_testc.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{34: 317, 203: 306, 146: 307, 3: 324, 106: 312, 75: 293, 87: 322, 99: 321, 116: 290, 98: 299, 148: 267, 41: 270, 63: 312, 174: 309, 62: 324, 171: 320, 127: 297, 95: 332, 196: 311, 81: 339, 35: 279, 38: 302, 220: 315, 176: 324, 175: 328, 48: 317, 161: 305, 193: 345, 188: 295, 107: 347, 37: 277, 102: 295, 5: 300, 1: 306, 212: 330, 65: 316, 159: 320, 133: 356, 211: 316, 60: 300, 103: 307, 169: 328, 187: 324, 124: 337, 40: 326, 36: 303, 184: 368, 190: 314, 28: 320, 30: 338, 167: 310, 217: 278, 119: 301, 20: 341, 100: 332, 55: 341, 57: 313, 26: 322, 56: 307, 27: 308, 110: 286, 182: 297, 73: 320, 25: 313, 162: 324, 23: 287, 172: 289, 143: 302, 54: 310, 15: 314, 179: 302, 125: 324, 183: 307, 153: 319, 18: 318, 151: 338, 189: 314, 219: 334, 144: 301, 94: 302, 135: 309, 147: 295, 86: 304, 24: 297, 121: 306, 200: 278, 66: 334, 105: 330, 180: 326, 79: 281, 142: 308, 14: 309, 210: 320, 50: 308, 108: 304, 9: 271, 21: 310, 222: 307, 181: 290, 42: 347, 194: 314, 214: 305, 2: 309, 130: 309, 80: 309, 78: 338, 218: 291, 145: 322, 163: 307, 111: 315, 70: 306, 112: 310, 123: 313, 32: 356, 74: 342, 229: 324, 117: 319, 109: 315, 29: 306, 11: 311, 132: 329, 53: 328, 165: 325, 61: 302, 47: 307, 225: 305, 136: 324, 134: 262, 201: 324, 72: 370, 197: 318, 149: 303, 115: 331, 6: 333, 168: 318, 141: 335, 206: 328, 126: 322, 17: 297, 71: 285, 185: 321, 139: 302, 22: 285, 88: 329, 76: 324, 166: 329, 89: 300, 67: 316, 46: 305, 77: 290, 228: 306, 13: 292, 51: 326, 96: 302, 224: 339, 226: 310, 137: 290, 8: 305, 7: 308, 31: 293, 44: 287, 208: 289, 59: 297, 204: 301, 58: 307, 101: 331, 170: 290, 221: 318, 207: 308, 128: 335, 82: 282, 69: 308, 154: 301, 173: 278, 164: 313, 152: 269, 64: 333, 19: 315, 90: 328, 209: 334, 223: 289, 150: 335, 113: 303, 39: 296, 138: 299, 93: 331, 85: 314, 91: 307, 156: 273, 120: 311, 199: 315, 191: 331, 104: 300, 122: 301, 155: 306, 186: 317, 198: 328, 216: 311, 215: 318, 192: 320, 230: 312, 0: 340, 160: 294, 16: 315, 4: 285, 12: 318, 92: 340, 97: 317, 140: 325, 68: 319, 227: 293, 205: 307, 49: 291, 45: 267, 158: 310, 131: 292, 52: 321, 157: 326, 178: 306, 195: 331, 10: 298, 129: 319, 43: 318, 33: 299, 114: 332, 177: 296, 202: 309, 118: 327, 84: 334, 213: 298, 83: 295}\n"
     ]
    }
   ],
   "source": [
    " #to find the fequnce of charcter image per class \n",
    "freqs = {}\n",
    "for i in y_train:\n",
    "    if i in freqs:\n",
    "                freqs[i] += 1\n",
    "                \n",
    "    else:\n",
    "        freqs[i] = 1\n",
    "\n",
    "print(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_per_class= collections.OrderedDict(sorted(freqs.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(0, 340),\n",
       "             (1, 306),\n",
       "             (2, 309),\n",
       "             (3, 324),\n",
       "             (4, 285),\n",
       "             (5, 300),\n",
       "             (6, 333),\n",
       "             (7, 308),\n",
       "             (8, 305),\n",
       "             (9, 271),\n",
       "             (10, 298),\n",
       "             (11, 311),\n",
       "             (12, 318),\n",
       "             (13, 292),\n",
       "             (14, 309),\n",
       "             (15, 314),\n",
       "             (16, 315),\n",
       "             (17, 297),\n",
       "             (18, 318),\n",
       "             (19, 315),\n",
       "             (20, 341),\n",
       "             (21, 310),\n",
       "             (22, 285),\n",
       "             (23, 287),\n",
       "             (24, 297),\n",
       "             (25, 313),\n",
       "             (26, 322),\n",
       "             (27, 308),\n",
       "             (28, 320),\n",
       "             (29, 306),\n",
       "             (30, 338),\n",
       "             (31, 293),\n",
       "             (32, 356),\n",
       "             (33, 299),\n",
       "             (34, 317),\n",
       "             (35, 279),\n",
       "             (36, 303),\n",
       "             (37, 277),\n",
       "             (38, 302),\n",
       "             (39, 296),\n",
       "             (40, 326),\n",
       "             (41, 270),\n",
       "             (42, 347),\n",
       "             (43, 318),\n",
       "             (44, 287),\n",
       "             (45, 267),\n",
       "             (46, 305),\n",
       "             (47, 307),\n",
       "             (48, 317),\n",
       "             (49, 291),\n",
       "             (50, 308),\n",
       "             (51, 326),\n",
       "             (52, 321),\n",
       "             (53, 328),\n",
       "             (54, 310),\n",
       "             (55, 341),\n",
       "             (56, 307),\n",
       "             (57, 313),\n",
       "             (58, 307),\n",
       "             (59, 297),\n",
       "             (60, 300),\n",
       "             (61, 302),\n",
       "             (62, 324),\n",
       "             (63, 312),\n",
       "             (64, 333),\n",
       "             (65, 316),\n",
       "             (66, 334),\n",
       "             (67, 316),\n",
       "             (68, 319),\n",
       "             (69, 308),\n",
       "             (70, 306),\n",
       "             (71, 285),\n",
       "             (72, 370),\n",
       "             (73, 320),\n",
       "             (74, 342),\n",
       "             (75, 293),\n",
       "             (76, 324),\n",
       "             (77, 290),\n",
       "             (78, 338),\n",
       "             (79, 281),\n",
       "             (80, 309),\n",
       "             (81, 339),\n",
       "             (82, 282),\n",
       "             (83, 295),\n",
       "             (84, 334),\n",
       "             (85, 314),\n",
       "             (86, 304),\n",
       "             (87, 322),\n",
       "             (88, 329),\n",
       "             (89, 300),\n",
       "             (90, 328),\n",
       "             (91, 307),\n",
       "             (92, 340),\n",
       "             (93, 331),\n",
       "             (94, 302),\n",
       "             (95, 332),\n",
       "             (96, 302),\n",
       "             (97, 317),\n",
       "             (98, 299),\n",
       "             (99, 321),\n",
       "             (100, 332),\n",
       "             (101, 331),\n",
       "             (102, 295),\n",
       "             (103, 307),\n",
       "             (104, 300),\n",
       "             (105, 330),\n",
       "             (106, 312),\n",
       "             (107, 347),\n",
       "             (108, 304),\n",
       "             (109, 315),\n",
       "             (110, 286),\n",
       "             (111, 315),\n",
       "             (112, 310),\n",
       "             (113, 303),\n",
       "             (114, 332),\n",
       "             (115, 331),\n",
       "             (116, 290),\n",
       "             (117, 319),\n",
       "             (118, 327),\n",
       "             (119, 301),\n",
       "             (120, 311),\n",
       "             (121, 306),\n",
       "             (122, 301),\n",
       "             (123, 313),\n",
       "             (124, 337),\n",
       "             (125, 324),\n",
       "             (126, 322),\n",
       "             (127, 297),\n",
       "             (128, 335),\n",
       "             (129, 319),\n",
       "             (130, 309),\n",
       "             (131, 292),\n",
       "             (132, 329),\n",
       "             (133, 356),\n",
       "             (134, 262),\n",
       "             (135, 309),\n",
       "             (136, 324),\n",
       "             (137, 290),\n",
       "             (138, 299),\n",
       "             (139, 302),\n",
       "             (140, 325),\n",
       "             (141, 335),\n",
       "             (142, 308),\n",
       "             (143, 302),\n",
       "             (144, 301),\n",
       "             (145, 322),\n",
       "             (146, 307),\n",
       "             (147, 295),\n",
       "             (148, 267),\n",
       "             (149, 303),\n",
       "             (150, 335),\n",
       "             (151, 338),\n",
       "             (152, 269),\n",
       "             (153, 319),\n",
       "             (154, 301),\n",
       "             (155, 306),\n",
       "             (156, 273),\n",
       "             (157, 326),\n",
       "             (158, 310),\n",
       "             (159, 320),\n",
       "             (160, 294),\n",
       "             (161, 305),\n",
       "             (162, 324),\n",
       "             (163, 307),\n",
       "             (164, 313),\n",
       "             (165, 325),\n",
       "             (166, 329),\n",
       "             (167, 310),\n",
       "             (168, 318),\n",
       "             (169, 328),\n",
       "             (170, 290),\n",
       "             (171, 320),\n",
       "             (172, 289),\n",
       "             (173, 278),\n",
       "             (174, 309),\n",
       "             (175, 328),\n",
       "             (176, 324),\n",
       "             (177, 296),\n",
       "             (178, 306),\n",
       "             (179, 302),\n",
       "             (180, 326),\n",
       "             (181, 290),\n",
       "             (182, 297),\n",
       "             (183, 307),\n",
       "             (184, 368),\n",
       "             (185, 321),\n",
       "             (186, 317),\n",
       "             (187, 324),\n",
       "             (188, 295),\n",
       "             (189, 314),\n",
       "             (190, 314),\n",
       "             (191, 331),\n",
       "             (192, 320),\n",
       "             (193, 345),\n",
       "             (194, 314),\n",
       "             (195, 331),\n",
       "             (196, 311),\n",
       "             (197, 318),\n",
       "             (198, 328),\n",
       "             (199, 315),\n",
       "             (200, 278),\n",
       "             (201, 324),\n",
       "             (202, 309),\n",
       "             (203, 306),\n",
       "             (204, 301),\n",
       "             (205, 307),\n",
       "             (206, 328),\n",
       "             (207, 308),\n",
       "             (208, 289),\n",
       "             (209, 334),\n",
       "             (210, 320),\n",
       "             (211, 316),\n",
       "             (212, 330),\n",
       "             (213, 298),\n",
       "             (214, 305),\n",
       "             (215, 318),\n",
       "             (216, 311),\n",
       "             (217, 278),\n",
       "             (218, 291),\n",
       "             (219, 334),\n",
       "             (220, 315),\n",
       "             (221, 318),\n",
       "             (222, 307),\n",
       "             (223, 289),\n",
       "             (224, 339),\n",
       "             (225, 305),\n",
       "             (226, 310),\n",
       "             (227, 293),\n",
       "             (228, 306),\n",
       "             (229, 324),\n",
       "             (230, 312)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=images_per_class.keys()\n",
    "y=images_per_class.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{134: 262}\n",
      "{72: 370}\n"
     ]
    }
   ],
   "source": [
    "# pprin the minmume/ maximum values  and its class label\n",
    "print( {key:value for key, value in freqs.items() if value == (min(freqs.values()))})\n",
    "print( {key:value for key, value in freqs.items() if value == (max(freqs.values()))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hoet-encoding of 231 classes\n",
    "Y_train =np_utils.to_categorical(y_train, 231)\n",
    "Y_test = np_utils.to_categorical(y_test, 231)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just one-hot-encoding (row/col--33/7 class)\n",
    "Y_trainr =np_utils.to_categorical(y_trainr, 33)\n",
    "Y_testr = np_utils.to_categorical(y_testr, 33)\n",
    "\n",
    "Y_trainc =np_utils.to_categorical(y_trainc, 7)\n",
    "Y_testc = np_utils.to_categorical(y_testc, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "g91yjhLhrH41"
   },
   "outputs": [],
   "source": [
    "the encoder layer \n",
    "def get_encoder(tune_layer=0):\n",
    "    base_model = tf.keras.applications.ResNet50(include_top=False,\n",
    "        weights='imagenet', input_shape=(32, 32, 3))\n",
    "    base_model.trainable = True\n",
    "#      if tune_layer>0:\n",
    "#         for layer in base_model.layers[:-tune_layer]:\n",
    "#             layer.trainable=False\n",
    "#     else:\n",
    "#         for layer in base_model.layers:\n",
    "#             layer.trainable = False\n",
    "            \n",
    "    inputs = tf.keras.layers.Input((32, 32, 3))\n",
    "    xm = base_model(inputs)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(xm)\n",
    "    x = tf.keras.layers.Dense(2048, activation='relu', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    z = tf.keras.layers.Dense(2048)(x)\n",
    "\n",
    "    f = tf.keras.Model(inputs, z)\n",
    "\n",
    "    return f, xm, base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 1, 1, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2048)              4194304   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2048)              4196352   \n",
      "=================================================================\n",
      "Total params: 31,986,560\n",
      "Trainable params: 31,929,344\n",
      "Non-trainable params: 57,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "get_encoder(0)[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "get_encoder(0)[2].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable_weights: 212\n",
      "non_trainable_weights: 106\n"
     ]
    }
   ],
   "source": [
    "get_encoder(0)[2]\n",
    "print(\"trainable_weights:\", len(get_encoder(0)[2].trainable_weights))\n",
    "print(\"non_trainable_weights:\", len(get_encoder(0)[2].non_trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KhGhjwwzr5yi",
    "outputId": "ff44cd06-e17f-411a-a43f-fcba43f8f32f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-13 17:52:00.089765: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 1, 1, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "=================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We now load up the pre-trained weights\n",
    "projection = get_encoder(0)[0]\n",
    "projection.load_weights('projection.h5')\n",
    "\n",
    "# Create a sub-model for extracting features\n",
    "rn50 = tf.keras.Model(projection.input, projection.layers[2].output)\n",
    "rn50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "fbSkm4NPsecS"
   },
   "outputs": [],
   "source": [
    "#231 classifier\n",
    "def get_linear_classifier_231(feature_backbone, trainable=False):\n",
    "    inputs = tf.keras.layers.Input(shape=(32, 32, 3))\n",
    "    \n",
    "    feature_backbone.trainable =  trainable\n",
    "    x = feature_backbone(inputs, training=False)\n",
    "    outputs = tf.keras.layers.Dense(231, activation=\"softmax\", )(x)\n",
    "    linear_model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    return linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DP-lW-7ms7Lj",
    "outputId": "34b76e31-6f6f-48af-ff03-3e15963d51fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "model_12 (Functional)        (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 231)               473319    \n",
      "=================================================================\n",
      "Total params: 24,061,031\n",
      "Trainable params: 473,319\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "get_linear_classifier_231(rn50).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "lBw85iBGs-Cm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "# Early Stopping to prevent overfitting and checkpoint to save model at each epoch231\n",
    "early_stopper = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", \n",
    "                                                 patience=5, verbose=2, \n",
    "                                                 restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('./model_simsiam_231/modelSimsiam231{epoch:01d}.hdf5', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BxH5ImyItN59",
    "outputId": "87b90427-fe76-472c-ac3a-f6778f7758ec"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_linear_classifier_231' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_56920/1339108300.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get linear model and compile 231\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_231\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linear_classifier_231\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrn50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m model_231.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"],\n\u001b[1;32m      5\u001b[0m                      optimizer=\"adam\")\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_linear_classifier_231' is not defined"
     ]
    }
   ],
   "source": [
    "# Get linear model and compile 231\n",
    "tf.keras.backend.clear_session()\n",
    "model_231 = get_linear_classifier_231(rn50)\n",
    "model_231.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"],\n",
    "                     optimizer=\"adam\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model for row/col\n",
    "tf.keras.backend.clear_session()\n",
    "model_rc = get_linear_classifierrc(rn50)\n",
    "model_rc.compile(loss=[\"categorical_crossentropy\",\"categorical_crossentropy\"], metrics=[\"accuracy\"],\n",
    "                     optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Functional)            (None, 2048)         23587712    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 33)           67617       model_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 7)            14343       model_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,669,672\n",
      "Trainable params: 81,960\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 132/2025 [>.............................] - ETA: 1:14:01 - loss: 17807.6680 - accuracy: 0.0109"
     ]
    }
   ],
   "source": [
    "# Train 231\n",
    "history = model_231.fit(x_train,Y_train,\n",
    "                 validation_split=0.1,\n",
    "                 other epochs=10,\n",
    "                 callbacks=[early_stopper,checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "model_12 (Functional)        (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 231)               473319    \n",
      "=================================================================\n",
      "Total params: 24,061,031\n",
      "Trainable params: 473,319\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    " model_231.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 14s 29ms/step - loss: 3080.2483 - accuracy: 0.6730\n"
     ]
    }
   ],
   "source": [
    "score_231 = model_231.evaluate(x_test,Y_test,batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3080.248291015625, 0.6729999780654907]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_231"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "y_pred = [np.argmax(p) for p in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33,)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_rc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6654/1629738445.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train row/col 33/7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model_rc.fit(x_train,[Y_trainr,Y_trainc],\n\u001b[0m\u001b[1;32m      3\u001b[0m                  \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  callbacks=[early_stopper,checkpoint])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_rc' is not defined"
     ]
    }
   ],
   "source": [
    "# Train row/col 33/7\n",
    "history = model_rc.fit(x_train,[Y_trainr,Y_trainc],\n",
    "                 validation_split=0.1,\n",
    "                 epochs=10,\n",
    "                 callbacks=[early_stopper,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_rc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6654/3084128541.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_rc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY_testr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_testc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_rc' is not defined"
     ]
    }
   ],
   "source": [
    "score = model_rc.evaluate(x_test,[Y_testr,Y_testc],batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test lossr: 754.4881591796875\n",
      "Test lossc: 643.5222778320312\n",
      "Test accuracyr: 0.6974999904632568\n",
      "Test accuracyc: 0.43312498927116394\n"
     ]
    }
   ],
   "source": [
    "print('Test lossr:', score[1])\n",
    "print('Test lossc:', score[2])\n",
    "print('Test accuracyr:', score[3])\n",
    "print('Test accuracyc:', score[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trr_acc = history.history['dense_accuracy']\n",
    "valr_acc = history.history['dense_1_accuracy']\n",
    "trc_acc = history.history['val_dense_accuracy']\n",
    "valc_acc = history.history['val_dense_1_accuracy']\n",
    "epochs=range(7)\n",
    "\n",
    "\n",
    "# to print training  accuracy vs validation accuracy\n",
    "plt.plot(epochs, trr_acc)\n",
    "plt.plot(epochs, valr_acc)\n",
    "plt.plot(epochs, trc_acc)\n",
    "plt.plot(epochs, valc_acc)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('row/col train_acc vs val_acc simsiam')\n",
    "plt.grid(True)\n",
    "plt.legend(['train-row-predictor', 'val-row-predictor','train-column-predictor', 'val-column-predictor'], loc='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMAleSaBYAAgM4+rTN5xy7y",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "SimSiam_Evaluation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
